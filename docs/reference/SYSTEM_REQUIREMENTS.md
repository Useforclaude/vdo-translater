# ğŸ’» System Requirements & Performance Analysis

**Date**: 2025-10-03
**Status**: Production Ready

---

## ğŸ“Š Resource Usage Breakdown

### ğŸ”µ **LIGHT Components** (à¸—à¸³à¸‡à¸²à¸™à¸šà¸™à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸›à¸à¸•à¸´à¹„à¸”à¹‰)

| Component | RAM | CPU | Disk | Speed |
|-----------|-----|-----|------|-------|
| **Context Analyzer** | ~100 MB | Low | 5 MB | Very Fast |
| **Translation Pipeline** | ~200 MB | Low | - | Fast |
| **Dictionary System** | ~10 MB | Low | 2 MB | Instant |
| **Idiom Detection** | ~50 MB | Low | - | Fast |
| **SRT Generation** | ~50 MB | Low | - | Instant |

**Total Light**: **~500 MB RAM**, CPU minimal

âœ… **à¹ƒà¸Šà¹‰à¸ªà¹€à¸›à¸„à¸™à¹‰à¸­à¸¢à¸¡à¸²à¸ à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸˜à¸£à¸£à¸¡à¸”à¸²à¸£à¸±à¸™à¹„à¸”à¹‰à¸ªà¸šà¸²à¸¢**

---

### ğŸ”´ **HEAVY Component** (à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸ªà¹€à¸›à¸„à¸ªà¸¹à¸‡)

| Component | RAM | CPU | Disk | GPU | Speed |
|-----------|-----|-----|------|-----|-------|
| **Whisper large-v3** | **10-12 GB** | High | **6 GB** | Optional | 1-2x realtime |

**Detail:**
- Model Size: **6 GB** (download once)
- Runtime RAM: **10-12 GB** (during transcription)
- CPU: High usage (à¹à¸™à¸°à¸™à¸³ 4+ cores)
- GPU: **Optional** but **10x faster** with CUDA

âš ï¸ **Whisper à¹ƒà¸Šà¹‰à¸ªà¹€à¸›à¸„à¹€à¸¢à¸­à¸°! à¹à¸™à¸°à¸™à¸³à¹ƒà¸Šà¹‰ Colab**

---

## ğŸ¯ Recommended Deployment Strategy

### âœ… **BEST APPROACH: Hybrid** (à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¸ªà¸¸à¸”!)

**à¹à¸¢à¸à¸‡à¸²à¸™à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸«à¸™à¸±à¸:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HEAVY WORK â†’ Google Colab (FREE GPU)      â”‚
â”‚  â”œâ”€ Whisper Transcription (10 GB RAM)      â”‚
â”‚  â””â”€ Output: Thai SRT + JSON                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ Download
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LIGHT WORK â†’ Local Machine                â”‚
â”‚  â”œâ”€ Context Analysis (100 MB)              â”‚
â”‚  â”œâ”€ Translation (200 MB)                    â”‚
â”‚  â”œâ”€ Idiom Detection (50 MB)                â”‚
â”‚  â””â”€ English SRT Generation                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œ:**
- âœ… Colab à¹ƒà¸«à¹‰ GPU **à¸Ÿà¸£à¸µ** (NVIDIA T4/P100)
- âœ… Whisper à¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™ **10-15 à¹€à¸—à¹ˆà¸²** à¸à¸±à¸š GPU
- âœ… Local à¹à¸›à¸¥à¹„à¸”à¹‰à¹€à¸£à¹‡à¸§ à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸­ Colab
- âœ… à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸„à¹ˆà¸² API

---

## ğŸ’° Cost Comparison

### Option A: All Local (à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¹à¸£à¸‡à¸à¸­)
```
Requirements:
- RAM: 16 GB+ (à¸ªà¸³à¸«à¸£à¸±à¸š Whisper)
- CPU: 8+ cores
- GPU: Optional (à¹à¸•à¹ˆà¸Šà¹‰à¸²à¸¡à¸²à¸ à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µ)

Cost: $0
Speed: 1-2x realtime (CPU only)
      10-20x realtime (with GPU)
```

### Option B: All Colab (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¸­à¸°à¹„à¸£)
```
Requirements:
- Google account
- Internet connection

Cost: $0 (Free tier)
      $10/month (Colab Pro - faster)
Speed: 10-20x realtime (GPU T4)
       30-50x realtime (Colab Pro - A100)
```

### Option C: Hybrid (à¹à¸™à¸°à¸™à¸³!)
```
Requirements:
- Colab: Whisper only
- Local: RAM 4 GB+, CPU normal

Cost: $0 (Whisper free on Colab)
      API cost for translation only
Speed: Best of both worlds!
```

---

## ğŸš€ Step-by-Step Guide for Colab

### **Part 1: Whisper Transcription on Colab**

**Create Colab Notebook:**

```python
# ===== CELL 1: Install =====
!pip install openai-whisper

# ===== CELL 2: Upload Video =====
from google.colab import files
uploaded = files.upload()  # Upload your video
video_file = list(uploaded.keys())[0]

# ===== CELL 3: Transcribe =====
import whisper
import json

# Load model (first time downloads 6 GB)
print("Loading Whisper large-v3...")
model = whisper.load_model("large-v3")

# Transcribe
print("Transcribing...")
result = model.transcribe(
    video_file,
    language="th",
    task="transcribe",
    word_timestamps=True,
    temperature=(0.0, 0.2, 0.4, 0.6, 0.8),
    beam_size=5,
    best_of=5
)

# Save results
output_file = video_file.replace('.mp4', '_transcript.json')
with open(output_file, 'w', encoding='utf-8') as f:
    json.dump(result, f, ensure_ascii=False, indent=2)

print(f"âœ“ Transcription saved: {output_file}")

# ===== CELL 4: Download Results =====
from google.colab import files
files.download(output_file)
```

**Time:**
- Upload video: 1-5 min (depends on size)
- First run: 5 min (download model)
- Transcribe: **10-20x realtime** (1 hour video = 3-6 minutes)
- Download: 1 min

**Total:** ~10 minutes for 1 hour video (first time)

---

### **Part 2: Translation on Local Machine**

**After downloading transcript from Colab:**

```bash
# 1. Put transcript in project folder
mv ~/Downloads/video_transcript.json input/

# 2. Run translation pipeline
.venv/bin/python src/translator_only.py \
  input/video_transcript.json \
  -o output/

# Output:
# - video_english.srt
# - video_context.json
# - video_stats.json
```

**Time:**
- Load idiom database: <1 sec
- Context analysis: 5-10 sec
- Translation: 30-60 sec (1 hour video)
- SRT generation: <1 sec

**Total:** ~1 minute for translation

---

## ğŸ“Š Performance Comparison

### 1 Hour Video Processing Time:

| Setup | Transcription | Translation | Total | Cost |
|-------|--------------|-------------|-------|------|
| **Local CPU only** | 60-120 min | 1 min | 61-121 min | $0 |
| **Local GPU (RTX)** | 3-6 min | 1 min | 4-7 min | $0 |
| **Colab Free** | 3-6 min | 1 min | 4-7 min | $0 |
| **Colab Pro** | 1-2 min | 1 min | 2-3 min | $10/mo |
| **Hybrid (Colab+Local)** | 3-6 min | 1 min | 4-7 min | $0 |

âœ… **à¹à¸™à¸°à¸™à¸³: Hybrid** - à¸Ÿà¸£à¸µ à¹à¸¥à¸°à¹€à¸£à¹‡à¸§!

---

## ğŸ’¾ Disk Space Requirements

### Minimum:
```
Whisper model: 6 GB (download once)
Project code: 50 MB
Dictionaries: 2 MB
Python packages: 500 MB
Temp files: 1-2 GB (per video)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: ~8.5 GB
```

### Recommended:
```
Same as minimum: 8.5 GB
+ Cache space: 5 GB
+ Output space: 10 GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: ~24 GB
```

**Colab:** à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸à¸±à¸‡à¸§à¸¥ à¸¡à¸µ storage à¸Ÿà¸£à¸µ 15-100 GB

---

## ğŸ¯ Which Option Should You Choose?

### âœ… **Use Colab If:**
- âœ… RAM < 16 GB
- âœ… No GPU
- âœ… Want maximum speed (10-20x)
- âœ… Don't want to install anything
- âœ… Occasional use

### âœ… **Use Local If:**
- âœ… RAM â‰¥ 16 GB
- âœ… Have GPU (NVIDIA)
- âœ… Frequent use (many videos)
- âœ… Privacy concerns
- âœ… No internet sometimes

### âœ… **Use Hybrid (BEST!) If:**
- âœ… Want best of both worlds
- âœ… Have internet
- âœ… Want to save local resources
- âœ… Need speed but don't have GPU

---

## ğŸ› ï¸ Setup Guide for Each Option

### **Option A: Full Colab Setup**

**Colab Notebook (All-in-One):**

```python
# Cell 1: Clone Project
!git clone https://github.com/your-repo/video-translater.git
%cd video-translater

# Cell 2: Install
!pip install openai-whisper openai python-dotenv pyyaml

# Cell 3: Upload .env
from google.colab import files
uploaded = files.upload()  # Upload .env with API key

# Cell 4: Upload Video
uploaded = files.upload()
video_file = list(uploaded.keys())[0]

# Cell 5: Run Full Pipeline
!python src/orchestrator.py {video_file} \
  --model large-v3 \
  --mode production \
  --device cuda

# Cell 6: Download Results
from google.colab import files
import os
for f in os.listdir('output'):
    files.download(f'output/{f}')
```

**Pros:**
- âœ… Everything in one place
- âœ… Free GPU
- âœ… No local installation

**Cons:**
- âŒ Need internet
- âŒ Session timeout (12 hours max)
- âŒ Upload/download every time

---

### **Option B: Hybrid Setup (Recommended!)**

**Step 1: Colab (Transcription Only)**

```python
# Simple transcription notebook
!pip install openai-whisper

from google.colab import files
uploaded = files.upload()
video = list(uploaded.keys())[0]

import whisper
model = whisper.load_model("large-v3")
result = model.transcribe(video, language="th", word_timestamps=True)

import json
with open('transcript.json', 'w') as f:
    json.dump(result, f, ensure_ascii=False, indent=2)

files.download('transcript.json')
```

**Step 2: Local (Translation Only)**

```bash
# Fast translation on local machine
.venv/bin/python scripts/translate_from_transcript.py \
  transcript.json \
  -o output/
```

**Pros:**
- âœ… Best speed (GPU transcription)
- âœ… Best flexibility (local translation)
- âœ… Save Colab session time
- âœ… Can tweak translation locally

**Cons:**
- âŒ Need 2 steps
- âŒ Need to download/upload transcript

---

## ğŸ“± Minimum System Requirements

### For Transcription:
| Spec | Minimum | Recommended | Colab |
|------|---------|-------------|-------|
| RAM | 16 GB | 32 GB | 12 GB (free) |
| CPU | 4 cores | 8+ cores | 2-4 cores |
| GPU | None | NVIDIA 8GB+ | T4 16GB (free) |
| Disk | 10 GB | 30 GB | Unlimited |

### For Translation Only:
| Spec | Minimum | Recommended |
|------|---------|-------------|
| RAM | 2 GB | 4 GB |
| CPU | 2 cores | 4 cores |
| Disk | 1 GB | 5 GB |

---

## ğŸ“ Quick Decision Guide

**à¸„à¸³à¸–à¸²à¸¡: à¸„à¸­à¸¡à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸¡à¸µ RAM à¹€à¸—à¹ˆà¸²à¹„à¸£?**

- **< 8 GB** â†’ à¹ƒà¸Šà¹‰ Colab à¹€à¸•à¹‡à¸¡à¸£à¸¹à¸›à¹à¸šà¸š (All Colab)
- **8-16 GB** â†’ à¹ƒà¸Šà¹‰ Hybrid (Colab + Local)
- **16+ GB + GPU** â†’ à¹ƒà¸Šà¹‰ Local à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
- **16+ GB à¹„à¸¡à¹ˆà¸¡à¸µ GPU** â†’ à¹ƒà¸Šà¹‰ Hybrid (à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸²)

---

## ğŸ’¡ Pro Tips

### Speed Up Colab:
```python
# Use GPU runtime
# Runtime â†’ Change runtime type â†’ GPU â†’ Save

# Check GPU
import torch
print(f"GPU: {torch.cuda.is_available()}")
print(f"GPU Name: {torch.cuda.get_device_name(0)}")
```

### Save Colab Session:
```python
# Mount Google Drive to save model
from google.colab import drive
drive.mount('/content/drive')

# Save model there (won't need to redownload)
import whisper
model = whisper.load_model("large-v3",
    download_root="/content/drive/MyDrive/whisper_models")
```

### Batch Processing:
```python
# Process multiple videos in one session
videos = ['video1.mp4', 'video2.mp4', 'video3.mp4']

for video in videos:
    result = model.transcribe(video, ...)
    # Save each result
```

---

## âœ… Final Recommendation

**à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸™à¸—à¸±à¹ˆà¸§à¹„à¸› (à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸›à¸à¸•à¸´):**
```
ğŸ¥‡ BEST: Hybrid Approach
   - Whisper on Colab (à¸Ÿà¸£à¸µ, à¹€à¸£à¹‡à¸§ 10-20x)
   - Translation on Local (à¹€à¸£à¹‡à¸§, à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸‡à¹ˆà¸²à¸¢)
   - Total time: 4-7 min per hour video
   - Cost: $0 (transcription) + $1.50-2.50 (translation API)
```

**à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸™à¸—à¸µà¹ˆà¸¡à¸µà¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¹à¸£à¸‡ (16GB+ RAM + GPU):**
```
ğŸ¥ˆ GOOD: Full Local
   - Everything on local machine
   - No internet dependency
   - Privacy
   - One-time setup
```

**à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸™à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸­à¸¢à¸²à¸à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¸­à¸°à¹„à¸£:**
```
ğŸ¥‰ OK: Full Colab
   - Zero installation
   - Everything online
   - Need good internet
   - 12 hour session limit
```

---

## ğŸ“ Need Help?

**Colab Setup Issues:**
- Check GPU is enabled
- Check CUDA is available
- Try restarting runtime

**Local Setup Issues:**
- Make sure use .venv
- Check RAM usage
- Try smaller Whisper model (medium/small)

**Performance Issues:**
- Use GPU if available
- Reduce Whisper model size
- Process shorter clips
- Use batch processing

---

**à¸ªà¸£à¸¸à¸›: à¸£à¸°à¸šà¸šà¸ªà¹ˆà¸§à¸™à¹ƒà¸«à¸à¹ˆà¹€à¸šà¸²à¸¡à¸²à¸ à¹ƒà¸Šà¹‰à¸ªà¹€à¸›à¸„à¸™à¹‰à¸­à¸¢ à¹à¸•à¹ˆ Whisper à¹ƒà¸Šà¹‰à¹€à¸¢à¸­à¸° à¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸£à¸±à¸™ Whisper à¸šà¸™ Colab (à¸Ÿà¸£à¸µ + à¹€à¸£à¹‡à¸§) à¹à¸¥à¹‰à¸§à¹à¸›à¸¥à¸ à¸²à¸©à¸²à¸šà¸™à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸•à¸±à¸§à¹€à¸­à¸‡!**

---

*Last Updated: 2025-10-03*
*Version: 1.0*
