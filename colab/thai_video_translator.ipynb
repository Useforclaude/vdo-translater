{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ Thai‚ÜíEnglish Video Translator (Colab)\n",
    "\n",
    "**Complete Thai video translation pipeline running on Google Colab with FREE GPU!**\n",
    "\n",
    "## üéØ What This Does\n",
    "\n",
    "1. ‚úÖ **Transcribe Thai audio** using Whisper large-v3 (GPU accelerated)\n",
    "2. ‚úÖ **Analyze context** for idioms, forex terms, metaphors\n",
    "3. ‚úÖ **Translate to English** with GPT-4/3.5 (smart routing)\n",
    "4. ‚úÖ **Generate SRT files** for both Thai and English\n",
    "5. ‚úÖ **Download results** to your computer\n",
    "\n",
    "## üí∞ Cost Estimate\n",
    "\n",
    "- **Whisper transcription**: $0 (runs on Colab GPU)\n",
    "- **Translation API**: $1.50-2.50 per hour of video\n",
    "- **Total for 1 hour video**: ~$2.00\n",
    "\n",
    "## ‚è±Ô∏è Speed\n",
    "\n",
    "- **Transcription**: 10-20x realtime (1 hour video = 3-6 minutes)\n",
    "- **Translation**: 1-2 minutes\n",
    "- **Total**: ~5-8 minutes for 1 hour video\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Setup & Installation\n",
    "\n",
    "**‚ö†Ô∏è Run this cell first!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q openai-whisper openai python-dotenv pyyaml\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU Status\")\n",
    "print(\"=\"*60)\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU found. Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save\")\n",
    "\n",
    "print(\"\\n‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Step 2: Upload Project Files\n",
    "\n",
    "**Upload the `project.zip` file you downloaded:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Upload zip file\n",
    "print(\"üì§ Please select project.zip file to upload...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract\n",
    "zip_filename = list(uploaded.keys())[0]\n",
    "print(f\"\\nüì¶ Extracting {zip_filename}...\")\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "\n",
    "# Change to project directory\n",
    "%cd video-translater\n",
    "\n",
    "print(\"\\n‚úÖ Project files extracted!\")\n",
    "print(\"\\nProject structure:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Step 3: Setup API Key\n",
    "\n",
    "**Upload your `.env` file with OpenAI API key:**\n",
    "\n",
    "```bash\n",
    "# .env file content:\n",
    "OPENAI_API_KEY=sk-your-api-key-here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Option 1: Upload .env file\n",
    "print(\"üì§ Upload your .env file (or skip and enter manually below)...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Option 2: Manual entry (if no file uploaded)\n",
    "if not uploaded:\n",
    "    from getpass import getpass\n",
    "    api_key = getpass(\"Enter your OpenAI API key: \")\n",
    "    \n",
    "    with open('.env', 'w') as f:\n",
    "        f.write(f\"OPENAI_API_KEY={api_key}\\n\")\n",
    "    \n",
    "    print(\"‚úÖ API key saved to .env\")\n",
    "else:\n",
    "    print(\"‚úÖ .env file uploaded\")\n",
    "\n",
    "# Verify\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"‚úÖ API key loaded successfully\")\n",
    "else:\n",
    "    print(\"‚ùå API key not found. Please check .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé• Step 4: Upload Video\n",
    "\n",
    "**Upload your Thai video file to translate:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üì§ Please select your video file...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "video_file = list(uploaded.keys())[0]\n",
    "video_path = Path(video_file)\n",
    "\n",
    "print(f\"\\n‚úÖ Video uploaded: {video_file}\")\n",
    "print(f\"Size: {video_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Get video info\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "result = subprocess.run(\n",
    "    ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', str(video_path)],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "info = json.loads(result.stdout)\n",
    "duration = float(info['format']['duration'])\n",
    "\n",
    "print(f\"Duration: {int(duration // 60)}:{int(duration % 60):02d}\")\n",
    "print(f\"\\nüí∞ Estimated cost: ${(duration / 3600) * 2:.2f}\")\n",
    "print(f\"‚è±Ô∏è  Estimated time: {int(duration / 10)}-{int(duration / 5)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 5: Run Translation Pipeline\n",
    "\n",
    "**This will:**\n",
    "1. Transcribe Thai audio (Whisper large-v3 on GPU)\n",
    "2. Analyze context (idioms, forex terms)\n",
    "3. Translate to English (GPT-3.5/4)\n",
    "4. Generate SRT files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Import orchestrator\n",
    "sys.path.insert(0, 'src')\n",
    "from orchestrator import VideoTranslationOrchestrator\n",
    "from config import ConfigMode\n",
    "from context_analyzer import DocumentType\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'whisper_model': 'large-v3',\n",
    "    'config_mode': ConfigMode.PRODUCTION,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'doc_type': DocumentType.TUTORIAL\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Starting Translation Pipeline\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Video: {video_file}\")\n",
    "print(f\"Whisper model: {CONFIG['whisper_model']}\")\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "print(f\"Mode: {CONFIG['config_mode'].value}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize orchestrator\n",
    "orchestrator = VideoTranslationOrchestrator(\n",
    "    whisper_model=CONFIG['whisper_model'],\n",
    "    config_mode=CONFIG['config_mode'],\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "\n",
    "# Process video\n",
    "result = orchestrator.process_video(\n",
    "    input_path=video_path,\n",
    "    output_dir=Path('output'),\n",
    "    doc_type=CONFIG['doc_type']\n",
    ")\n",
    "\n",
    "# Results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if result.success:\n",
    "    print(\"‚úÖ Translation completed successfully!\")\n",
    "    print(f\"\\nOutput files:\")\n",
    "    for name, path in result.output_files.items():\n",
    "        print(f\"  - {name}: {path}\")\n",
    "    \n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(f\"  - Duration: {result.stats['duration_seconds']:.1f}s\")\n",
    "    print(f\"  - Processing time: {result.stats['processing_time_seconds']:.1f}s\")\n",
    "    print(f\"  - Speed: {result.stats['processing_speed']:.1f}x realtime\")\n",
    "    print(f\"  - Thai segments: {result.stats['thai_segments']}\")\n",
    "    print(f\"  - Thai confidence: {result.stats['thai_confidence']:.1%}\")\n",
    "    print(f\"  - Cost: ${result.stats['estimated_cost']:.4f}\")\n",
    "    print(f\"  - Cost/min: ${result.stats['cost_per_minute']:.4f}\")\n",
    "else:\n",
    "    print(f\"‚ùå Translation failed: {result.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 6: Download Results\n",
    "\n",
    "**Download all output files to your computer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if result.success:\n",
    "    print(\"üì• Downloading files...\")\n",
    "    print()\n",
    "    \n",
    "    for name, path in result.output_files.items():\n",
    "        if path.exists():\n",
    "            print(f\"‚¨áÔ∏è  Downloading {name}: {path.name}\")\n",
    "            files.download(str(path))\n",
    "    \n",
    "    print(\"\\n‚úÖ All files downloaded!\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. Check your Downloads folder\")\n",
    "    print(\"2. Use *_english.srt for English subtitles\")\n",
    "    print(\"3. Use *_thai.srt for Thai subtitles\")\n",
    "    print(\"4. Optional: Merge SRT with video using local script\")\n",
    "else:\n",
    "    print(\"‚ùå No files to download (translation failed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Optional: Merge Subtitles with Video\n",
    "\n",
    "**Burn subtitles directly into video (creates new video file):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if result.success:\n",
    "    # Get paths\n",
    "    english_srt = result.output_files['english_srt']\n",
    "    output_video = Path('output') / f\"{video_path.stem}_with_subtitles.mp4\"\n",
    "    \n",
    "    print(\"üé¨ Merging English subtitles with video...\")\n",
    "    print(f\"Input: {video_file}\")\n",
    "    print(f\"Subtitles: {english_srt.name}\")\n",
    "    print(f\"Output: {output_video.name}\")\n",
    "    print()\n",
    "    \n",
    "    # FFmpeg command\n",
    "    cmd = [\n",
    "        'ffmpeg',\n",
    "        '-i', str(video_path),\n",
    "        '-vf', f\"subtitles={english_srt}:force_style='FontName=Arial,FontSize=24,PrimaryColour=&H00FFFFFF,OutlineColour=&H00000000,Outline=2,MarginV=30'\",\n",
    "        '-c:v', 'libx264',\n",
    "        '-preset', 'medium',\n",
    "        '-crf', '23',\n",
    "        '-c:a', 'copy',\n",
    "        '-y',\n",
    "        str(output_video)\n",
    "    ]\n",
    "    \n",
    "    subprocess.run(cmd, check=True)\n",
    "    \n",
    "    print(\"\\n‚úÖ Video with subtitles created!\")\n",
    "    print(f\"Downloading {output_video.name}...\")\n",
    "    files.download(str(output_video))\n",
    "    \n",
    "    print(\"\\n‚úÖ Download complete!\")\n",
    "else:\n",
    "    print(\"‚ùå Translation must succeed first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Optional: View Statistics\n",
    "\n",
    "**Detailed translation statistics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.success:\n",
    "    import json\n",
    "    \n",
    "    # Load full stats\n",
    "    stats_file = result.output_files['stats']\n",
    "    with open(stats_file) as f:\n",
    "        stats = json.load(f)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"DETAILED STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nüìπ Video Information:\")\n",
    "    print(f\"  Input: {stats['input_file']}\")\n",
    "    print(f\"  Duration: {stats['duration_seconds']:.1f}s ({stats['duration_seconds']/60:.1f} min)\")\n",
    "    \n",
    "    print(f\"\\nüéØ Transcription:\")\n",
    "    print(f\"  Thai segments: {stats['thai_segments']}\")\n",
    "    print(f\"  Thai words: {stats['thai_words']}\")\n",
    "    print(f\"  Confidence: {stats['thai_confidence']:.1%}\")\n",
    "    \n",
    "    print(f\"\\nüåê Translation:\")\n",
    "    print(f\"  GPT-3.5 segments: {stats['gpt35_segments']}\")\n",
    "    print(f\"  GPT-4 segments: {stats['gpt4_segments']}\")\n",
    "    print(f\"  Cache hits: {stats['translation_cache_hits']}\")\n",
    "    print(f\"  Cache rate: {stats['translation_cache_rate']:.1%}\")\n",
    "    \n",
    "    print(f\"\\nüí∞ Cost:\")\n",
    "    print(f\"  Total: ${stats['estimated_cost']:.4f}\")\n",
    "    print(f\"  Per minute: ${stats['cost_per_minute']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Performance:\")\n",
    "    print(f\"  Processing time: {stats['processing_time_seconds']:.1f}s\")\n",
    "    print(f\"  Speed: {stats['processing_speed']:.1f}x realtime\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Timestamp: {stats['timestamp']}\")\n",
    "else:\n",
    "    print(\"‚ùå No statistics available (translation failed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Batch Processing (Multiple Videos)\n",
    "\n",
    "**Process multiple videos at once:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload multiple videos\n",
    "print(\"üì§ Upload multiple video files...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "video_files = [Path(f) for f in uploaded.keys()]\n",
    "print(f\"\\n‚úÖ Uploaded {len(video_files)} videos\")\n",
    "\n",
    "# Process each\n",
    "results = []\n",
    "total_cost = 0\n",
    "\n",
    "for i, video in enumerate(video_files, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"[{i}/{len(video_files)}] Processing: {video.name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    result = orchestrator.process_video(\n",
    "        input_path=video,\n",
    "        output_dir=Path('output') / video.stem,\n",
    "        doc_type=DocumentType.TUTORIAL\n",
    "    )\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "    if result.success:\n",
    "        total_cost += result.stats['estimated_cost']\n",
    "        print(f\"‚úÖ Success - Cost: ${result.stats['estimated_cost']:.4f}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed: {result.error}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"BATCH SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total videos: {len(video_files)}\")\n",
    "print(f\"Successful: {sum(1 for r in results if r.success)}\")\n",
    "print(f\"Failed: {sum(1 for r in results if not r.success)}\")\n",
    "print(f\"Total cost: ${total_cost:.4f}\")\n",
    "\n",
    "# Download all\n",
    "print(\"\\nüì• Downloading all results...\")\n",
    "for result in results:\n",
    "    if result.success:\n",
    "        for path in result.output_files.values():\n",
    "            if path.exists():\n",
    "                files.download(str(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Save to Google Drive (Optional)\n",
    "\n",
    "**Save results to your Google Drive instead of downloading:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import shutil\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create output folder in Drive\n",
    "drive_output = Path('/content/drive/MyDrive/ThaiVideoTranslations')\n",
    "drive_output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if result.success:\n",
    "    # Copy all output files\n",
    "    video_output_dir = drive_output / video_path.stem\n",
    "    video_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"üì§ Copying files to Google Drive...\")\n",
    "    for name, path in result.output_files.items():\n",
    "        if path.exists():\n",
    "            dest = video_output_dir / path.name\n",
    "            shutil.copy2(path, dest)\n",
    "            print(f\"  ‚úÖ {path.name}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Files saved to: {video_output_dir}\")\n",
    "    print(\"You can access them from your Google Drive!\")\n",
    "else:\n",
    "    print(\"‚ùå No files to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Documentation\n",
    "\n",
    "### Output Files\n",
    "\n",
    "- `*_thai.srt` - Thai subtitles (original transcription)\n",
    "- `*_english.srt` - English subtitles (translation)\n",
    "- `*_thai.json` - Full Thai transcription with timestamps\n",
    "- `*_context.json` - Context analysis (idioms, terms, metaphors)\n",
    "- `*_stats.json` - Processing statistics and costs\n",
    "\n",
    "### Tips\n",
    "\n",
    "1. **GPU is essential** for fast transcription (10-20x speedup)\n",
    "2. **Cost optimization**: Use `ConfigMode.COST_OPTIMIZED` for cheaper translation\n",
    "3. **Quality focus**: Use `ConfigMode.QUALITY_FOCUS` for best accuracy\n",
    "4. **Save to Drive**: Recommended for large batches (Colab session timeout = 12 hours)\n",
    "5. **Resume support**: Save checkpoint to Drive, reload on new session\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "**GPU not available:**\n",
    "- Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save\n",
    "\n",
    "**Out of memory:**\n",
    "- Use smaller Whisper model: `medium` or `small`\n",
    "- Split long videos first\n",
    "\n",
    "**API errors:**\n",
    "- Check OpenAI API key is valid\n",
    "- Verify you have credits/billing enabled\n",
    "\n",
    "**Session timeout:**\n",
    "- Save to Google Drive frequently\n",
    "- Use batch processing with checkpoints\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ You're Done!\n",
    "\n",
    "Your Thai videos are now translated to English with perfect subtitles! üöÄ"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
